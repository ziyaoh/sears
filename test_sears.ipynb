{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # here\n",
    "# Path to sears repository\n",
    "sys.path.append('sears') # noqa\n",
    "import paraphrase_scorer\n",
    "import onmt_model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ID 0\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "ps = paraphrase_scorer.ParaphraseScorer(gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import replace_rules\n",
    "tokenizer = replace_rules.Tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "all_data = pickle.load(open('polarity.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "data = all_data['data']\n",
    "labels = all_data['labels']\n",
    "label_names = all_data['label_names']\n",
    "val = all_data['imdb']\n",
    "val_labels = all_data['imdb_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump({'data': data, 'labels': labels, 'label_names': label_names, 'imdb': val, 'imdb_labels': val_labels}, open('/tmp/polarity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.clean_for_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "# val, val_labels, _ = load_polarity_imdb()\n",
    "clean_val = tokenizer.clean_for_model(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train sequence length: 36\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.6878 - acc: 0.5882\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.6299 - acc: 0.7926\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.5024 - acc: 0.8827\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.3702 - acc: 0.9326\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.2674 - acc: 0.9630\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.1947 - acc: 0.9807\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.1438 - acc: 0.9885\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.1082 - acc: 0.9930\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0828 - acc: 0.9958\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0645 - acc: 0.9971\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "model = fasttext.FastTextClassifier()\n",
    "w.fit(data, labels, ngram_range=2, epochs=10, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (model.predict(clean_val) == val_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_for_onmt = [' '.join([a.text for a in x]) for x in nlp.tokenizer.pipe(val)]\n",
    "# val_for_onmt = [onmt_model.clean_text(x, only_upper=False) for x in val_for_onmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "right = np.where(model.predict(clean_val) == val_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "right_preds = np.array([val_labels[i] for i in right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "def find_flips(instance, model, topk=10, threshold=-10, ):\n",
    "    orig_pred = model.predict([instance])[0]\n",
    "    instance_for_onmt = onmt_model.clean_text(' '.join([x.text for x in nlp.tokenizer(instance)]), only_upper=False)\n",
    "    paraphrases = ps.generate_paraphrases(instance_for_onmt, topk=topk, edit_distance_cutoff=4, threshold=threshold)\n",
    "    texts = tokenizer.clean_for_model(tokenizer.clean_for_humans([x[0] for x in paraphrases]))\n",
    "    preds = model.predict(texts)\n",
    "    fs = [(texts[i], paraphrases[i][1]) for i in np.where(preds != orig_pred)[0]]\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "# compute SEA\n",
    "import collections\n",
    "orig_scores = {}\n",
    "flips = collections.defaultdict(lambda: [])\n",
    "print(len(right))\n",
    "for i, idx in enumerate(right):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    if val[idx] in flips:\n",
    "        continue\n",
    "    fs = find_flips(val[idx], model, topk=100, threshold=-10)\n",
    "    flips[val[idx]].extend([x[0] for x in fs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "right_val = [clean_val[i] for i in right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "tr2 = replace_rules.TextToReplaceRules(nlp, right_val, [], min_freq=0.005, min_flip=0.00, ngram_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "# extract rules from SEA\n",
    "frequent_rules = []\n",
    "rule_idx = {}\n",
    "rule_flips = {}\n",
    "for z, f in enumerate(flips):\n",
    "    rules = tr2.compute_rules(f, flips[f], use_pos=True, use_tags=True)\n",
    "    for rs in rules:\n",
    "        for r in rs:\n",
    "            if r.hash() not in rule_idx:\n",
    "                i = len(rule_idx)\n",
    "                rule_idx[r.hash()] = i\n",
    "                rule_flips[i] = []\n",
    "                frequent_rules.append(r)\n",
    "            i = rule_idx[r.hash()]\n",
    "            rule_flips[i].append(z)\n",
    "    if z % 500 == 0:\n",
    "        print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "token_right = tokenizer.tokenize(right_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "model_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(frequent_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n",
      "110000\n",
      "115000\n",
      "120000\n",
      "125000\n",
      "130000\n",
      "135000\n",
      "140000\n",
      "145000\n",
      "150000\n",
      "155000\n",
      "160000\n",
      "165000\n",
      "170000\n",
      "175000\n",
      "180000\n",
      "185000\n",
      "190000\n",
      "195000\n",
      "200000\n",
      "205000\n",
      "210000\n",
      "215000\n",
      "220000\n",
      "225000\n",
      "230000\n",
      "235000\n",
      "273.9192931652069\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "a = time.time()\n",
    "rule_flips = {}\n",
    "rule_other_texts = {}\n",
    "rule_other_flips = {}\n",
    "rule_applies = {}\n",
    "for i, r in enumerate(frequent_rules):\n",
    "    idxs = list(tr2.get_rule_idxs(r))\n",
    "    to_apply = [token_right[x] for x in idxs]\n",
    "    applies, nt = r.apply_to_texts(to_apply, fix_apostrophe=False)\n",
    "    applies = [idxs[x] for x in applies]\n",
    "    old_texts = [right_val[i] for i in applies]\n",
    "    old_labels = right_preds[applies]\n",
    "    to_compute = [x for x in nt if x not in model_preds]\n",
    "    if to_compute:\n",
    "        preds = model.predict(to_compute)\n",
    "        for x, y in zip(to_compute, preds):\n",
    "            model_preds[x] = y\n",
    "    new_labels = np.array([model_preds[x] for x in nt])\n",
    "    where_flipped = np.where(new_labels != old_labels)[0]\n",
    "    flips = sorted([applies[x] for x in where_flipped])\n",
    "    rule_flips[i] = flips\n",
    "    rule_other_texts[i] = nt\n",
    "    rule_other_flips[i] = where_flipped\n",
    "    rule_applies[i] = applies\n",
    "    if i % 5000 == 0:\n",
    "        print(i)\n",
    "print(time.time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "really_frequent_rules = [i for i in range(len(rule_flips)) if len(rule_flips[i]) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_compute_score = collections.defaultdict(lambda: set())\n",
    "# for i in really_frequent_rules:\n",
    "#     orig_texts =  [right_val[z] for z in rule_applies[i]]\n",
    "#     new_texts = rule_other_texts[i]\n",
    "#     for o, n in zip(orig_texts, new_texts):\n",
    "#         to_compute_score[o].add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "threshold = -7.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "orig_scores = {}\n",
    "for i, t in enumerate(right_val):\n",
    "    orig_scores[i] = ps.score_sentences(t, [t])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want rules s.t. the decile > -7.15. The current bottom 10% of a rule is always a lower bound on the decile, so if I see applies / 10 with score < -7.15 I can stop computing scores for that rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "ps_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "ps.last = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171442\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "6000\n",
      "7000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "17000\n",
      "18000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "30000\n",
      "31000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "84000\n",
      "85000\n",
      "89000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "153000\n",
      "154000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "176000\n",
      "177000\n",
      "179000\n",
      "180000\n",
      "183000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "191000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "223000\n",
      "224000\n",
      "226000\n",
      "227000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "rule_scores = []\n",
    "rejected = set()\n",
    "print(len(really_frequent_rules))\n",
    "for idx, i in enumerate(really_frequent_rules):\n",
    "    orig_texts =  [right_val[z] for z in rule_applies[i]]\n",
    "    orig_scor = [orig_scores[z] for z in rule_applies[i]]\n",
    "    scores = np.ones(len(orig_texts)) * -50\n",
    "#     if idx in rejected:\n",
    "#         rule_scores.append(scores)\n",
    "#         continue\n",
    "    decile = np.ceil(.1 * len(orig_texts))\n",
    "    new_texts = rule_other_texts[i]\n",
    "    bad_scores = 0\n",
    "    for j, (o, n, orig) in enumerate(zip(orig_texts, new_texts, orig_scor)):\n",
    "        if o not in ps_scores:\n",
    "            ps_scores[o] = {}\n",
    "        if n not in ps_scores[o]:\n",
    "            if n == '':\n",
    "                score = -40\n",
    "            else:\n",
    "                score = ps.score_sentences(o, [n])[0]\n",
    "            ps_scores[o][n] = min(0, score - orig)\n",
    "        scores[j] = ps_scores[o][n]\n",
    "        if ps_scores[o][n] < threshold:\n",
    "            bad_scores += 1\n",
    "        if bad_scores >= decile:\n",
    "            rejected.add(idx)\n",
    "            break\n",
    "    rule_scores.append(scores)\n",
    "            \n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump({'ps_scores': ps_scores, 'orig_scores': orig_scores}, open('/home/marcotcr/tmp/polarity_scoresz.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rule_scores) - len(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "rule_flip_scores = [rule_scores[i][rule_other_flips[really_frequent_rules[i]]] for i in range(len(rule_scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "frequent_flips = [np.array(rule_applies[i])[rule_other_flips[i]] for i in really_frequent_rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "rule_precsupports = [len(rule_applies[i]) for i in really_frequent_rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "from rule_picking import disqualify_rules\n",
    "threshold=-7.15\n",
    "# x = choose_rules_coverage(fake_scores, frequent_flips, frequent_supports,\n",
    "disqualified = disqualify_rules(rule_scores, frequent_flips,\n",
    "                          rule_precsupports, \n",
    "                      min_precision=0.0, min_flips=6, \n",
    "                         min_bad_score=threshold, max_bad_proportion=.10,\n",
    "                          max_bad_sum=999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(i, x.hash()) for (i, x) in enumerate(frequent_rules) if 'text_movie -> text_film' in x.hash()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3288688659667969\n",
      "Instances flipped: 77 (0.10)\n",
      "0     6000  7245  film -> movie                       f:17 avg_s:0.57 bad_s:0.03 bad_sum:3 Prec:0.15 Supp:0.15\n",
      "1     56940 69756 movie -> film                       f:10 avg_s:0.75 bad_s:0.06 bad_sum:7 Prec:0.08 Supp:0.16\n",
      "2     3588  4482  acting -> performance               f:6 avg_s:0.70 bad_s:0.05 bad_sum:2 Prec:0.15 Supp:0.05\n",
      "3     129143 175592 PRON is DET -> it 's DET            f:7 avg_s:0.60 bad_s:0.06 bad_sum:1 Prec:0.44 Supp:0.02\n",
      "4     91380 119755 DET movie -> the film               f:7 avg_s:0.56 bad_s:0.07 bad_sum:6 Prec:0.08 Supp:0.12\n",
      "5     6003  7248  this film -> this movie             f:6 avg_s:0.92 bad_s:0.03 bad_sum:1 Prec:0.21 Supp:0.04\n",
      "6     27748 34267 great -> major                      f:7 avg_s:0.14 bad_s:0.07 bad_sum:2 Prec:0.26 Supp:0.04\n",
      "7     26527 31957 is -> was                           f:32 avg_s:0.02 bad_s:0.04 bad_sum:9 Prec:0.13 Supp:0.31\n",
      "8     92025 120528 It is -> He 's                      f:6 avg_s:0.13 bad_s:0.08 bad_sum:1 Prec:0.46 Supp:0.02\n",
      "9     118511 160878 DET NN -> the NN                    f:10 avg_s:0.03 bad_s:0.08 bad_sum:35 Prec:0.02 Supp:0.58\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "# finalize SEARs\n",
    "from rule_picking import choose_rules_coverage\n",
    "threshold=-7.15\n",
    "a = time.time()\n",
    "x = choose_rules_coverage(rule_flip_scores, frequent_flips, None,\n",
    "                          None, len(right_preds),\n",
    "                                frequent_scores_on_all=None, k=10, metric='max',\n",
    "                      min_precision=0.0, min_flips=0, exp=True,\n",
    "                         min_bad_score=threshold, max_bad_proportion=.1,\n",
    "                          max_bad_sum=999999,\n",
    "                         disqualified=disqualified,\n",
    "                         start_from=[])\n",
    "print(time.time() -a)\n",
    "support_denominator = float(len(right_preds))\n",
    "soup = lambda x: len(rule_applies[really_frequent_rules[x]]) / support_denominator \n",
    "prec = lambda x: frequent_flips[x].shape[0] / float(len(rule_scores[x]))\n",
    "fl = len(set([a for r in x for a in frequent_flips[r]]))\n",
    "print('Instances flipped: %d (%.2f)' % (fl, fl / float(len(right_preds))))\n",
    "print('\\n'.join(['%-5d %-5d %-5d %-35s f:%d avg_s:%.2f bad_s:%.2f bad_sum:%d Prec:%.2f Supp:%.2f' % (\n",
    "                i, x[i], really_frequent_rules[r],\n",
    "                frequent_rules[really_frequent_rules[r]].hash().replace('text_', '').replace('pos_', '').replace('tag_', ''),\n",
    "                frequent_flips[r].shape[0],\n",
    "                np.exp(rule_flip_scores[r]).mean(), (rule_scores[r] < threshold).mean(),\n",
    "                (rule_scores[r] < threshold).sum(), prec(r), soup(r)) for i, r in enumerate(x)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a couple of examples from the first rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: text_film -> text_movie\n",
      "\n",
      "Yes , this film does require a rather significant amount of puzzle - solving , but the pieces fit together to create a beautiful picture .\n",
      "P(positive):0.58\n",
      "\n",
      "Yes , this movie does require a rather significant amount of puzzle - solving , but the pieces fit together to create a beautiful picture .\n",
      "P(positive):0.37\n",
      "\n",
      "\n",
      "Overall , the film is interesting and thought - provoking .\n",
      "P(positive):0.67\n",
      "\n",
      "Overall , the movie is interesting and thought - provoking .\n",
      "P(positive):0.50\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_movie -> text_film\n",
      "\n",
      "A very , very , very slow - moving , aimless movie about a distressed , drifting young man .\n",
      "P(positive):0.40\n",
      "\n",
      "A very , very , very slow - moving , aimless film about a distressed , drifting young man .\n",
      "P(positive):0.54\n",
      "\n",
      "\n",
      "Yeah , the movie pretty much sucked .\n",
      "P(positive):0.31\n",
      "\n",
      "Yeah , the film pretty much sucked .\n",
      "P(positive):0.51\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_acting -> text_performance\n",
      "\n",
      "The acting is terrible , and the writing is worse .\n",
      "P(positive):0.30\n",
      "\n",
      "The performance is terrible , and the writing is worse .\n",
      "P(positive):0.53\n",
      "\n",
      "\n",
      "The acting sucked .\n",
      "P(positive):0.37\n",
      "\n",
      "The performance sucked .\n",
      "P(positive):0.51\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: pos_PRON text_is pos_DET -> text_it text_'s pos_DET\n",
      "\n",
      "The performances are not improved by improvisation , because the actors now have twice as much to worry about : not only whether they 're delivering the line well , but whether the line itself is any good .\n",
      "P(positive):0.39\n",
      "\n",
      "The performances are not improved by improvisation , because the actors now have twice as much to worry about : not only whether they're delivering the line well , but whether the line it's any good .\n",
      "P(positive):0.57\n",
      "\n",
      "\n",
      "The acting helps the writing along very well ( maybe the idiot - savant sister could have been played better ) , and it is a real joy to watch .\n",
      "P(positive):0.71\n",
      "\n",
      "The acting helps the writing along very well ( maybe the idiot - savant sister could have been played better ) , and it's a real joy to watch .\n",
      "P(positive):0.67\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: pos_DET text_movie -> text_the text_film\n",
      "\n",
      "Yeah , the movie pretty much sucked .\n",
      "P(positive):0.31\n",
      "\n",
      "Yeah , the film pretty much sucked .\n",
      "P(positive):0.51\n",
      "\n",
      "\n",
      "This movie suffered because of the writing , it needed more suspense .\n",
      "P(positive):0.43\n",
      "\n",
      "the film suffered because of the writing , it needed more suspense .\n",
      "P(positive):0.58\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_this text_film -> text_this text_movie\n",
      "\n",
      "Yes , this film does require a rather significant amount of puzzle - solving , but the pieces fit together to create a beautiful picture .\n",
      "P(positive):0.58\n",
      "\n",
      "Yes , this movie does require a rather significant amount of puzzle - solving , but the pieces fit together to create a beautiful picture .\n",
      "P(positive):0.37\n",
      "\n",
      "\n",
      "If good intentions made a film great , then this film might be one of the greatest films ever made .\n",
      "P(positive):0.70\n",
      "\n",
      "If good intentions made a film great , then this movie might be one of the greatest films ever made .\n",
      "P(positive):0.47\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_great -> text_major\n",
      "\n",
      "A great film by a great director .\n",
      "P(positive):0.62\n",
      "\n",
      "A major film by a great director .\n",
      "P(positive):0.37\n",
      "\n",
      "\n",
      "The movie I received was a great quality film for it 's age .\n",
      "P(positive):0.52\n",
      "\n",
      "The movie I received was a major quality film for it's age .\n",
      "P(positive):0.36\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_is -> text_was\n",
      "\n",
      "It is an insane game .\n",
      "P(positive):0.78\n",
      "\n",
      "It was an insane game .\n",
      "P(positive):0.39\n",
      "\n",
      "\n",
      "If you want a movie that 's not gross but gives you some chills , this is a great choice .\n",
      "P(positive):0.73\n",
      "\n",
      "If you want a movie that's not gross but gives you some chills , this was a great choice .\n",
      "P(positive):0.47\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: text_It text_is -> text_He text_'s\n",
      "\n",
      "It is an insane game .\n",
      "P(positive):0.78\n",
      "\n",
      "He's an insane game .\n",
      "P(positive):0.66\n",
      "\n",
      "\n",
      "It is not just a cult ... it is a cult CLASSIC .\n",
      "P(positive):0.56\n",
      "\n",
      "He's not just a cult ... it is a cult CLASSIC .\n",
      "P(positive):0.53\n",
      "\n",
      "\n",
      "---------------\n",
      "Rule: pos_DET tag_NN -> text_the tag_NN\n",
      "\n",
      "No actress has been worse used that June Allison in this movie .\n",
      "P(positive):0.38\n",
      "\n",
      "the actress has been worse used that June Allison in this movie .\n",
      "P(positive):0.51\n",
      "\n",
      "\n",
      "All things considered , a job very well done .\n",
      "P(positive):0.56\n",
      "\n",
      "All things considered , the job very well done .\n",
      "P(positive):0.46\n",
      "\n",
      "\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# here\n",
    "for r in x:\n",
    "    rid = really_frequent_rules[r]\n",
    "    rule =  frequent_rules[rid]\n",
    "    print('Rule: %s' % rule.hash())\n",
    "    print()\n",
    "    for f in rule_flips[rid][:2]:\n",
    "        print('%s\\nP(positive):%.2f' % (right_val[f], model.predict_proba([right_val[f]])[0, 1]))\n",
    "        print()\n",
    "        new = rule.apply(token_right[f])[1]\n",
    "        print('%s\\nP(positive):%.2f' % (new, model.predict_proba([new])[0, 1]))\n",
    "        print()\n",
    "        print()\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_DET tag_NN -> text_the tag_NN\n",
      "(True, 'Who is watching the movie ?')\n"
     ]
    }
   ],
   "source": [
    "question = 'Who is watching a movie?'\n",
    "token_q = tokenizer.tokenize([question])\n",
    "new = rule.apply(token_q[0])\n",
    "print(rule.hash())\n",
    "print(new)\n",
    "\n",
    "# token_q\n",
    "# token_right[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The plane was late and the detectives were waiting for the airport every morning .',\n",
       " 'The plane was late and the detectives were waiting for the airport all morning .',\n",
       " 'The airplane was late and the detectives were waiting for the airport every morning .',\n",
       " 'The plane was late and the detectives were waiting at the airport all morning .',\n",
       " 'The plane was late and the detectives were waiting at the airport every morning .',\n",
       " 'The airplane was late and the detectives were waiting for the airport all morning .',\n",
       " 'The plane was late and detectives were waiting for the airport every morning .',\n",
       " 'The plane was late and the detectives were expecting the airport every morning .',\n",
       " 'The plane was late , and the detectives were waiting for the airport every morning .',\n",
       " 'The plane was late , and the detectives were waiting for the airport all morning .']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paraphrase_instance(instance, topk=10, threshold=-10, ):\n",
    "#     orig_pred = model.predict([instance])[0]\n",
    "    instance_for_onmt = onmt_model.clean_text(' '.join([x.text for x in nlp.tokenizer(instance)]), only_upper=False)\n",
    "    paraphrases = ps.generate_paraphrases(instance_for_onmt, topk=topk, edit_distance_cutoff=4, threshold=threshold)\n",
    "    texts = tokenizer.clean_for_model(tokenizer.clean_for_humans([x[0] for x in paraphrases]))\n",
    "    return texts\n",
    "#     preds = model.predict(texts)\n",
    "#     fs = [(texts[i], paraphrases[i][1]) for i in np.where(preds != orig_pred)[0]]\n",
    "#     return fs\n",
    "\n",
    "paraphrase_instance('The plane was late and the detectives were waiting at the airport all morning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rule_scores.pkl', 'rb') as f:\n",
    "    new_rule_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([(a==b).all() for a, b in zip(new_rule_scores, rule_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sears",
   "language": "python",
   "name": "sears"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
